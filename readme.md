## Описание
В лабораторной работе реализуются методы логистической регрессии и K-ближайших соседей для классификации пациентов с заболеваниями сердца.

## Структура

- `raw/` - реализации алгоритмов с нуля
- `sklearn/` - реализации с использованием scikit-learn
- `metrics.py` - общие метрики оценки качества
- `heart.csv` - датасет (предполагаемый файл данных)

## Логистическая регрессия
В качестве лосса была выбрана функция кросс-энтропии, найдены производные по параметрам w и b для корректного апдейта при градентном спуске. Для нормализации предсказанных значений была использован сигмоидная функция.
Все остальное не отличалось от реализации в лр 2, код из которой был переиспользован (mini-batch GD)

## K-ближайших соседей
Алгоритм K ближайших соседей классифицирует вектор на основе самых частых классов, встречающихся у его соседей. Для нахождения данного расстояния использовал косинусное расстояние.


# Метрики
## 1. Логистическая регрессия:
На тестовой выборке:
  Accuracy: 0.7951
  Precision: 0.7563
  Recall: 0.8738
  AUC-ROC: 0.8793
  Confusion Matrix:
    [73 29]
    [13 90]

## 2. KNN
На тестовой выборке:
    k=1
        Accuracy: 0.9854,
        Precision: 1.0000
        Recall: 0.9709
        [102 0]
        [3 100]

    k=3
        Accuracy: 0.9024
        Precision: 0.8952
        Recall: 0.9126
        [91 11]
        [9 94]
    k=5
        Accuracy: 0.7317
        Precision: 0.7308
        Recall: 0.7379
        [74 28]
        [27 76]
    k=7
        Accuracy: 0.6780
        Precision: 0.6796
        Recall: 0.6796
        [69 33]
        [33 70]
    k=9
        Accuracy: 0.7171
        Precision: 0.6923
        Recall: 0.7864
        [66 36]
        [22 81]


# Результаты sklearn

## 1. Логистическая регрессия:
На тестовой выборке:
    Accuracy:  0.8098
    Precision: 0.7619
    Recall:    0.9143
    AUC-ROC:   0.9298

    Confusion Matrix:
    [70 30]
    [9 96]

## 2. KNN
    k=1
        Accuracy:  1.0000
        Precision: 1.0000
        Recall:    1.0000
        Confusion Matrix:
        [100 0]
        [0 105]

    k=3
        Accuracy:  0.9463
        Precision: 0.9352
        Recall:    0.9619
        Confusion Matrix:
        [93 7]
        [4 101]

    k=5
        Accuracy:  0.8634
        Precision: 0.8738
        Recall:    0.8571
        Confusion Matrix:
        [87 13]
        [15 90]

    k=7
        Accuracy:  0.8439
        Precision: 0.8230
        Recall:    0.8857
        Confusion Matrix:
        [80 20]
        [12 93]

    k=9
        Accuracy:  0.8537
        Precision: 0.8319
        Recall:    0.8952
        Confusion Matrix:
        [81 19]
        [11 94]


# Выводы
Как и ожидалось, решения sklearn оказались существенно точнее кастомных алгоритмов.
Для логистической регрессии разницу можно заметить в реколле и auc-roc (метрики оказались на 5-10% выше), но в целом реализация "с нуля" справляется с поставленной задачей так же, как и фреймворк.

Для KNN разница более существенна - странная аномалия в виде precision = 1 при k=1 и последующий дроп качества при увеличении k. Кажется, ошибка где-то в реализации подбора ближайших классов, так как чем больше k - тем больше падает качество ответов модели.


# Описание классов
### 1. K-ближайших соседей (KNN)

#### Raw реализация (`raw/knn.py`)
- **Класс**: `KNN`
- **Алгоритм**: K-ближайших соседей реализован с нуля
- **Метрики расстояния**: евклидово, манхэттена, косинусное
- **Методы класса**:
  - `fit()` - обучение модели (сохранение тренировочных данных)
  - `predict()` - предсказание меток
  - `predict_single()` - предсказание для одного образца
  - `score()` - точность модели
  - `precision()` - метрика точности
  - `recall()` - метрика полноты
  - `get_confusion_matrix()` - матрица ошибок

#### Sklearn реализация (`sklearn/knn.py`)
- **Класс**: `KNeighborsClassifier`
- **Особенности**:
  - Использование шкалирования StandardScaler
  - Тестирование разных значений k
  - Кросс-валидация
  - Визуализация результатов
  - Сравнение разных метрик расстояния

### 2. Логистическая регрессия

#### Raw реализация (`raw/lr.py`)
- **Класс**: `LogisticRegression`
- **Алгоритм**: Логистическая регрессия с мини-батч градиентным спуском
- **Функция потерь**: кросс-энтропия
- **Методы класса**:
  - `fit()` - обучение с мини-батч градиентным спуском
  - `_sigmoid()` - сигмоидная функция активации
  - `predict()` - предсказание меток классов
  - `predict_proba()` - предсказание вероятностей
  - `score()` - точность модели
  - `precision()` - метрика точности
  - `recall()` - метрика полноты
  - `auc_roc()` - AUC-ROC метрика
  - `get_confusion_matrix()` - матрица ошибок

#### Sklearn реализация (`sklearn/lr.py`)
- **Класс**: `LogisticRegression`
- **Особенности**:
  - Использование шкалирования StandardScaler
  - Регуляризация (параметр C)
  - ROC-кривая и AUC
  - Визуализация важности признаков
  - Кросс-валидация

## Общие метрики (`metrics.py`)

- `confusion_matrix()` - матрица ошибок
- `accuracy_score()` - точность
- `precision_score()` - точность (precision)
- `recall_score()` - полнота (recall)
- `classification_report()` - полный отчет о метриках
- `show_classification_report()` - отображение отчета

## Датасет

**heart.csv** - датасет заболеваний сердца со следующими признаками:

- `age` - возраст в годах
- `sex` - (1 = мужчина; 0 = женщина)
- `cp` - тип боли в груди
- `trestbps` - артериальное давление в покое (в мм рт. ст.)
- `chol` - уровень холестерина в сыворотке крови (в мг/дл)
- `fbs` - уровень сахара в крови натощак > 120 мг/дл (1 = истина; 0 = ложь)
- `restecg` - результаты покойной электрокардиографии
- `thalach` - максимальный достигнутый пульс
- `exang` - стенокардия, вызванная физической нагрузкой (1 = да; 0 = нет)
- `oldpeak` - депрессия ST, вызванная физической нагрузкой
- `slope` - наклон пикового сегмента ST при физической нагрузке
- `ca` - количество крупных сосудов (0-3), окрашенных флюороскопией
- `thal` - 3 = норма; 6 = фиксированный дефект; 7 = обратимый дефект
- `target` - наличие болезни или нет (1 = да, 0 = нет)

## Запуск

Для запуска реализаций необходимо:

1. Убедиться, что `heart.csv` находится в нужной директории
2. Установить зависимости (для sklearn версий):
   ```bash
   pip install pandas numpy scikit-learn matplotlib
   ```
3. Запустить нужный файл:
   ```bash
   python raw/knn.py
   python sklearn/lr.py
   ```

## Метрики оценки

Все модели оцениваются по следующим метрикам:
- **Accuracy (Точность)**: доля правильных предсказаний
- **Precision (Точность)**: TP / (TP + FP)
- **Recall (Полнота)**: TP / (TP + FN)
- **AUC-ROC**: площадь под ROC-кривой
- **Confusion Matrix**: матрица ошибок
